version: '3.9'

services:
  web:
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/code
    ports:
      - "8000:8000"
    environment:
      DEBUG: 'True'
      DATABASE_URL: postgres://root:root@db:5432/db
    depends_on:
      - db
    restart: unless-stopped
    networks:
      - app_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000"]
      interval: 10s
      timeout: 30s
      retries: 5
      start_period: 10s

  db:
    container_name: postgres_container
    image: postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: root
      POSTGRES_DB: db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app_network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "root"]
      interval: 10s
      timeout: 30s
      retries: 5
      start_period: 10s

  pgadmin:
    container_name: pgadmin4_container
    image: dpage/pgadmin4
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: root
    ports:
      - "5050:80"
    networks:
      - app_network
    depends_on:
      - db

  ollama:
    container_name: ollama
    restart: unless-stopped
    image: ollama/ollama:latest
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - "./ollamadata:/root/.ollama"
    ports:
      - 11434:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 30s
      retries: 5
      start_period: 10s
    depends_on:
      web:
        condition: service_healthy
      db:
        condition: service_healthy
      ollama-models-pull:
        condition: service_started
    networks:
      - app_network
    entrypoint: ["/bin/bash", "-c", "until ollama list; do sleep 5; done && ollama run llama3.2"]

  ollama-models-pull:
    container_name: ollama-models-pull
    image: curlimages/curl:latest
    command: >
      curl -X POST http://ollama:11434/api/pull -d '{"name":"llama3.2"}'
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - app_network

networks:
  app_network:
    driver: bridge

volumes:
  postgres_data:
  ollamadata:
