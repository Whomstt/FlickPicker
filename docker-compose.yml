services:
  django-app:
    container_name: fyp-django-app
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/code
    ports:
      - "8000:8000"
    environment:
      DEBUG: 'True'
    restart: unless-stopped
    networks:
      - app_network

  ollama:
    container_name: fyp-ollama
    restart: unless-stopped
    image: ollama/ollama:latest
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - "./ollamadata:/root/.ollama"
    ports:
      - 11434:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - app_network
    entrypoint: ["/bin/bash", "-c"]
    command: |
      "ollama serve && \
      ollama pull llama3.2 && \
      ollama pull nomic-embed-text"
      

networks:
  app_network:
    driver: bridge

volumes:
  ollamadata: